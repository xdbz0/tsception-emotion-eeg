# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HcMMFSR_2K0qT4FZKlVE-iLnE8tVVJJk
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
!pip install nbimporter
import nbimporter

import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
from tqdm import tqdm

import sys
project_dir = '/content/drive/MyDrive/eeeg_emotion_detect_project'
sys.path.append(project_dir)

!jupyter nbconvert --to python data_loader.ipynb
import data_loader as dl

# !jupyter nbconvert --to python utils.ipynb
# import utils
# from utils import plot_training_curves, plot_confusion_matrix, filter_frequency_bands

# %run /content/drive/MyDrive/eeeg_emotion_detect_project/utils.ipynb

# Check for GPU availability
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Configuration parameters
# project_dir = '/content/drive/MyDrive/eeeg_emotion_detect_project'
CSV_PATH = os.path.join(project_dir, 'emotions.csv')
BATCH_SIZE = 64
LEARNING_RATE = 1e-3
EPOCHS = 50
PATIENCE = 5  # Early stopping patience parameter
RANDOM_SEED = 42
USE_FILTERED_BANDS = True  # Use frequency band filtering

# ----- Define TinyTSception model with channel attention -----
class TinyTSception(nn.Module):
   def __init__(self, feat_dim, classes):
       super().__init__()
       self.conv = nn.Sequential(
           nn.Conv2d(1, 16, kernel_size=(1,3), padding=(0,1)),
           nn.ReLU(),
           nn.Conv2d(16,32, kernel_size=(1,15), padding=(0,7)),
           nn.ReLU(),
           nn.AdaptiveAvgPool2d((1,1))
       )

       # Channel attention mechanism
       self.attention = nn.Sequential(
           nn.Linear(32, 16),
           nn.ReLU(),
           nn.Linear(16, 32),
           nn.Sigmoid()
       )

       self.fc = nn.Linear(32, classes)

   def forward(self, x):  # x:(B,1,1,feat)
       # Apply convolutions
       x = self.conv(x)

       # Apply channel attention
       b, c, h, w = x.size()
       y = x.view(b, c)
       y = self.attention(y).view(b, c, 1, 1)
       x = x * y  # Apply attention weights

       # Classification
       x = x.view(x.size(0), -1)
       return self.fc(x)

def train_model():
   """
   Main training function with early stopping and filtered frequency bands
   """
   print("Starting model training with early stopping and frequency filtering...")

   # ----- Load and preprocess data -----
   print("Loading data...")
   X, y, label_map = dl.load_eeg_feature_csv(CSV_PATH)

   # Log original data statistics
   print(f"Original data shape: {X.shape}")
   print(f"Class distribution: {np.bincount(y)}")
   print(f"Label mapping: {label_map}")

   # Apply frequency band filtering if enabled
   if USE_FILTERED_BANDS:
       print("Applying frequency band filtering...")
       X_filtered = filter_frequency_bands(X)
       print(f"Filtered data shape: {X_filtered.shape}")

       # Save both raw and filtered signals for comparison
       raw_sample = X[0, :20]
       filtered_sample = X_filtered[0, :20]
       plt.figure(figsize=(12, 6))
       plt.plot(raw_sample, label='Raw')
       plt.plot(filtered_sample, label='Filtered')
       plt.legend()
       plt.title('Raw vs Filtered Signal Comparison')
       plt.savefig(os.path.join(project_dir, 'signal_comparison.png'))

       # Use filtered data for training
       X = X_filtered

   # Normalize features
   Xn, stats = dl.normalize_features(X)
   print(f"Data normalized. Mean: {stats['mean'].mean():.4f}, Std: {stats['std'].mean():.4f}")

   # Reshape for TSception
   Xn = dl.reshape_for_tsception_feature(Xn)

   # Split into training and validation sets
   X_tr, X_val, y_tr, y_val = train_test_split(
       Xn, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED
   )
   print(f"Train set: {X_tr.shape}, Validation set: {X_val.shape}")

   # Create PyTorch datasets and data loaders
   def to_tensor(arr, dtype=torch.float32):
       return torch.from_numpy(arr).to(dtype)

   ds_tr = TensorDataset(to_tensor(X_tr), torch.from_numpy(y_tr))
   ds_val = TensorDataset(to_tensor(X_val), torch.from_numpy(y_val))
   dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True)
   dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE)

   # Get input dimension and number of classes
   input_dim = Xn.shape[-1]
   num_classes = int(np.max(y) + 1)

   # ----- Initialize model -----
   model = TinyTSception(input_dim, num_classes)
   model.to(device)

   # ----- Training setup -----
   criterion = nn.CrossEntropyLoss()
   optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

   # ----- Early stopping variables -----
   best_f1 = 0.0
   best_acc = 0.0
   best_model_path = os.path.join(project_dir, 'best_day3.pth')
   patience_counter = 0
   history = {
       'train_loss': [],
       'val_loss': [],
       'val_f1': [],
       'val_acc': []
   }

   # ----- Training loop -----
   print("Starting training...")
   for epoch in range(1, EPOCHS + 1):
       # Training phase
       model.train()
       train_losses = []

       for xb, yb in tqdm(dl_tr, desc=f"Epoch {epoch:02d} [train]"):
           xb, yb = xb.to(device), yb.to(device)

           # Forward pass
           optimizer.zero_grad()
           outputs = model(xb)
           loss = criterion(outputs, yb)

           # Backward pass and optimization
           loss.backward()
           optimizer.step()

           train_losses.append(loss.item())

       # Calculate average training loss
       avg_train_loss = np.mean(train_losses)
       history['train_loss'].append(avg_train_loss)

       # Validation phase
       model.eval()
       val_losses = []
       preds, gold = [], []

       with torch.no_grad():
           for xb, yb in dl_val:
               xb, yb = xb.to(device), yb.to(device)

               # Forward pass
               outputs = model(xb)
               loss = criterion(outputs, yb)

               # Store predictions and ground truth
               preds.extend(outputs.argmax(1).cpu().numpy())
               gold.extend(yb.cpu().numpy())
               val_losses.append(loss.item())

       # Calculate validation metrics
       avg_val_loss = np.mean(val_losses)
       val_f1 = f1_score(gold, preds, average='macro')
       val_acc = accuracy_score(gold, preds)

       # Update history
       history['val_loss'].append(avg_val_loss)
       history['val_f1'].append(val_f1)
       history['val_acc'].append(val_acc)

       # Print metrics
       print(f"Epoch {epoch:02d} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val F1: {val_f1:.4f} | Val Acc: {val_acc:.4f}")

       # Check if performance improved
       if val_f1 > best_f1:
           best_f1 = val_f1
           best_acc = val_acc

           # Save best model
           torch.save({
               'epoch': epoch,
               'model_state_dict': model.state_dict(),
               'optimizer_state_dict': optimizer.state_dict(),
               'val_f1': val_f1,
               'val_acc': val_acc,
               'train_loss': avg_train_loss,
               'val_loss': avg_val_loss
           }, best_model_path)

           print(f"New best model saved with F1: {val_f1:.4f}, Acc: {val_acc:.4f}")
           patience_counter = 0
       else:
           patience_counter += 1
           print(f"No improvement for {patience_counter} epochs")

       # Early stopping check
       if patience_counter >= PATIENCE:
           print(f"Early stopping triggered after {epoch} epochs")
           break

   # ----- Post-training -----
   print("Training complete!")
   print(f"Best validation F1: {best_f1:.4f}, Accuracy: {best_acc:.4f}")

   # Plot training curves
   plot_training_curves(history, save_path=os.path.join(project_dir, 'training_curves.png'))

   # Generate confusion matrix for best model
   model.load_state_dict(torch.load(best_model_path, weights_only=False)['model_state_dict'])
   model.eval()

   with torch.no_grad():
       all_preds, all_gold = [], []
       for xb, yb in DataLoader(ds_val, batch_size=BATCH_SIZE):
           xb, yb = xb.to(device), yb.to(device)
           outputs = model(xb)
           all_preds.extend(outputs.argmax(1).cpu().numpy())
           all_gold.extend(yb.cpu().numpy())

   # Plot confusion matrix
   cm = confusion_matrix(all_gold, all_preds)
   plot_confusion_matrix(cm, list(label_map.keys()), save_path=os.path.join(project_dir, 'confusion_matrix.png'))

   return best_f1, best_acc, history

if __name__ == "__main__":
   train_model()