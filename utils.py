# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zb1fWIaw3AkDxlhQEZzeVd25JkgyZns9
"""

# -*- coding: utf-8 -*-
"""
utils.py - Utility functions for EEG emotion recognition
Enhanced for Day 3 with early stopping, visualization and filtering utilities
"""

import os
import time
import pprint
import numpy as np
import torch
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, ConfusionMatrixDisplay
from scipy import signal

# Basic utilities
def set_gpu(x):
    """Set specific GPU to use"""
    torch.set_num_threads(1)
    os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
    os.environ['CUDA_VISIBLE_DEVICES'] = x
    print('using gpu:', x)

def seed_all(seed):
    """Set random seeds for reproducibility"""
    torch.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    np.random.seed(seed)

def ensure_path(path):
    """Create directory if it doesn't exist"""
    if os.path.exists(path):
        pass
    else:
        os.makedirs(path)

class Averager():
    """Simple averaging class for tracking metrics"""
    def __init__(self):
        self.n = 0
        self.v = 0

    def add(self, x):
        self.v = (self.v * self.n + x) / (self.n + 1)
        self.n += 1

    def item(self):
        return self.v

def count_acc(logits, label):
    """Calculate accuracy from logits"""
    pred = torch.argmax(logits, dim=1)
    return (pred == label).type(torch.cuda.FloatTensor).mean().item()

class Timer():
    """Simple timer for tracking execution time"""
    def __init__(self):
        self.o = time.time()

    def measure(self, p=1):
        x = (time.time() - self.o) / p
        x = int(x)
        if x >= 3600:
            return '{:.1f}h'.format(x / 3600)
        if x >= 60:
            return '{}m'.format(round(x / 60))
        return '{}s'.format(x)

_utils_pp = pprint.PrettyPrinter()
def pprint(x):
    _utils_pp.pprint(x)

def get_model(args):
    """Get model based on arguments"""
    from networks import TSception

    if args.model == 'TSception':
        model = TSception(
            num_classes=args.num_class, input_size=args.input_shape,
            sampling_rate=args.sampling_rate, num_T=args.T, num_S=args.T,
            hidden=args.hidden, dropout_rate=args.dropout)
    return model

def get_dataloader(data, label, batch_size, shuffle=True):
    """Create DataLoader from data and labels"""
    from torch.utils.data import DataLoader, TensorDataset

    # Create PyTorch dataset from NumPy arrays
    if isinstance(data, np.ndarray):
        data = torch.from_numpy(data).float()
    if isinstance(label, np.ndarray):
        label = torch.from_numpy(label).long()

    dataset = TensorDataset(data, label)
    loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=True)
    return loader

def get_metrics(y_pred, y_true, classes=None):
    """Calculate accuracy, F1 score and confusion matrix"""
    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average='macro')
    if classes is not None:
        cm = confusion_matrix(y_true, y_pred, labels=classes)
    else:
        cm = confusion_matrix(y_true, y_pred)
    return acc, f1, cm

def get_trainable_parameter_num(model):
    """Count trainable parameters in model"""
    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total_params

def L1Loss(model, Lambda):
    """Calculate L1 regularization loss"""
    w = torch.cat([x.view(-1) for x in model.parameters()])
    err = Lambda * torch.sum(torch.abs(w))
    return err

def generate_TS_channel_order(original_order: list):
    """
    Generate the channel order for TSception

    Parameters
    ----------
    original_order: list of the channel names

    Returns
    -------
    TS: list of channel names which is for TSception
    """
    chan_name, chan_num, chan_final = [], [], []
    for channel in original_order:
        chan_name_len = len(channel)
        k = 0
        for s in [*channel[:]]:
            if s.isdigit():
               k += 1
        if k != 0:
            chan_name.append(channel[:chan_name_len-k])
            chan_num.append(int(channel[chan_name_len-k:]))
            chan_final.append(channel)
    chan_pair = []
    for ch, id in enumerate(chan_num):
        if id % 2 == 0:
            chan_pair.append(chan_name[ch] + str(id-1))
        else:
            chan_pair.append(chan_name[ch] + str(id+1))
    chan_no_duplicate = []
    [chan_no_duplicate.extend([f, chan_pair[i]]) for i, f in enumerate(chan_final) if f not in chan_no_duplicate]
    return chan_no_duplicate[0::2] + chan_no_duplicate[1::2]

# ----- New functions for optimizing model -----

def plot_training_curves(history, save_path=None):
    """
    Plot training and validation curves

    Parameters:
    - history: Dictionary with training history
        Required keys: ['train_loss', 'val_loss', 'val_f1', 'val_acc']
    - save_path: Path to save the figure (if None, don't save)
    """
    plt.figure(figsize=(15, 5))

    # Plot training & validation loss
    plt.subplot(1, 3, 1)
    plt.plot(history['train_loss'], label='Train')
    plt.plot(history['val_loss'], label='Validation')
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    # Plot validation F1
    plt.subplot(1, 3, 2)
    plt.plot(history['val_f1'], label='F1')
    plt.title('Validation F1 Score')
    plt.xlabel('Epoch')
    plt.ylabel('F1 Score')

    # Plot validation accuracy
    plt.subplot(1, 3, 3)
    plt.plot(history['val_acc'], label='Accuracy')
    plt.title('Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path)
        print(f"Training curves saved to {save_path}")

    plt.show()

def plot_confusion_matrix(cm, class_names, save_path=None):
    """
    Plot confusion matrix

    Parameters:
    - cm: Confusion matrix (from sklearn.metrics.confusion_matrix)
    - class_names: List of class names
    - save_path: Path to save the figure (if None, don't save)
    """
    plt.figure(figsize=(8, 6))

    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap='Blues', values_format='.2f')

    plt.title('Confusion Matrix')
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path)
        print(f"Confusion matrix saved to {save_path}")

    plt.show()

def filter_frequency_bands(X, bands_to_keep=None, sampling_rate=128):
    """
    Filter EEG data into specific frequency bands

    Parameters:
    - X: EEG data (samples x features)
    - bands_to_keep: List of frequency bands to keep ('delta', 'theta', 'alpha', 'beta', 'gamma')
    - sampling_rate: Sampling rate of EEG data

    Returns:
    - X_filtered: Filtered data
    """
    # Default bands to keep
    if bands_to_keep is None:
        bands_to_keep = ['alpha', 'beta', 'theta']  # Most relevant for emotion

    # Define frequency bands
    bands = {
        'delta': (1, 4),    # Delta waves: 1-4 Hz (deep sleep)
        'theta': (4, 8),    # Theta waves: 4-8 Hz (drowsiness, meditation)
        'alpha': (8, 13),   # Alpha waves: 8-13 Hz (relaxed awareness)
        'beta': (13, 30),   # Beta waves: 13-30 Hz (active thinking)
        'gamma': (30, 45)   # Gamma waves: >30 Hz (cognitive processing)
    }

    # Create a copy to avoid modifying original data
    X_filtered = np.zeros_like(X)

    for feature_idx in range(X.shape[1]):
        feature_included = False

        # Check if this feature might be part of a selected band
        for band in bands_to_keep:
            # Simple heuristic for our dataset - this is just a placeholder
            if band in ['alpha', 'beta'] and feature_idx % 3 == 0:
                X_filtered[:, feature_idx] = X[:, feature_idx] * 1.2  # Emphasize
                feature_included = True
            elif band in ['theta'] and feature_idx % 5 == 0:
                X_filtered[:, feature_idx] = X[:, feature_idx] * 1.1  # Slightly emphasize
                feature_included = True

        # Include other features with less emphasis
        if not feature_included:
            X_filtered[:, feature_idx] = X[:, feature_idx] * 0.8  # De-emphasize

    return X_filtered

def apply_bandpass_filter(X, low_freq, high_freq, sampling_rate=128, order=4):
    """
    Apply Butterworth bandpass filter to EEG data

    Parameters:
    - X: EEG data (time series)
    - low_freq: Lower cutoff frequency
    - high_freq: Upper cutoff frequency
    - sampling_rate: Sampling rate of EEG data
    - order: Filter order

    Returns:
    - X_filtered: Filtered data
    """
    nyquist = 0.5 * sampling_rate
    low = low_freq / nyquist
    high = high_freq / nyquist

    # Design Butterworth bandpass filter
    b, a = signal.butter(order, [low, high], btype='band')

    # Apply filter
    X_filtered = signal.filtfilt(b, a, X, axis=0)

    return X_filtered

class EarlyStopping:
    """
    Early stopping to terminate training when validation loss doesn't improve

    Parameters:
    - patience: Number of epochs to wait after last improvement
    - verbose: Whether to print messages
    - delta: Minimum change to qualify as improvement
    - path: Path to save the checkpoint
    - trace_func: Function to print messages
    """
    def __init__(self, patience=5, verbose=True, delta=0, path='checkpoint.pt', trace_func=print):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.inf
        self.delta = delta
        self.path = path
        self.trace_func = trace_func

    def __call__(self, val_loss, model):
        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose:
                self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        """Save model when validation loss decreases"""
        if self.verbose:
            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')
        torch.save(model.state_dict(), self.path)
        self.val_loss_min = val_loss

def visualize_attention_weights(attention_weights, channel_names=None, save_path=None):
    """
    Visualize channel attention weights

    Parameters:
    - attention_weights: Attention weights for each channel
    - channel_names: List of channel names (if None, uses indices)
    - save_path: Path to save the figure (if None, don't save)
    """
    plt.figure(figsize=(10, 6))

    # If channel names not provided, use indices
    if channel_names is None:
        channel_names = [f'Ch{i+1}' for i in range(len(attention_weights))]

    # Plot attention weights
    plt.bar(channel_names, attention_weights)
    plt.title('Channel Attention Weights')
    plt.xlabel('Channel')
    plt.ylabel('Weight')
    plt.xticks(rotation=45)
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path)
        print(f"Attention weights visualization saved to {save_path}")

    plt.show()

def compare_band_performance(band_results, save_path=None):
    """
    Compare performance across different frequency bands

    Parameters:
    - band_results: Dictionary mapping band combinations to performance metrics
      e.g., {'alpha': 0.75, 'alpha+beta': 0.82, ...}
    - save_path: Path to save the figure (if None, don't save)
    """
    bands = list(band_results.keys())
    accuracies = list(band_results.values())

    plt.figure(figsize=(10, 6))
    plt.bar(bands, accuracies)
    plt.title('Performance by Frequency Band Combination')
    plt.xlabel('Frequency Bands')
    plt.ylabel('Accuracy')
    plt.ylim(0, 1.0)
    plt.xticks(rotation=45)
    plt.tight_layout()

    if save_path:
        plt.savefig(save_path)
        print(f"Band performance comparison saved to {save_path}")

    plt.show()

# Example usage
if __name__=="__main__":
    # Example of using generate_TS_channel_order()
    original_order = ['Fp1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3', 'P7', 'PO3',
                     'O1', 'Oz', 'Pz', 'Fp2', 'AF4', 'Fz', 'F4', 'F8', 'FC6', 'FC2', 'Cz', 'C4', 'T8', 'CP6',
                     'CP2', 'P4', 'P8', 'PO4', 'O2']
    TS = generate_TS_channel_order(original_order)
    print('done')

    # Example of early stopping
    early_stopping = EarlyStopping(patience=5, verbose=True)
    # In training loop: early_stopping(val_loss, model)